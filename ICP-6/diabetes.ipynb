{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTSLQQri1hpa",
        "outputId": "e449f5c8-a0b8-4748-8c0a-59cc5f3d825d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv = '/content/gdrive/My Drive/Neural-Networks/diabetes.csv'"
      ],
      "metadata": {
        "id": "uzcdt2MD1sha"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  1.Using the use case in class"
      ],
      "metadata": {
        "id": "-oPbyB403FNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "# load dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv(path_to_csv, header=None).values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],\n",
        "                                                    test_size=0.25, random_state=87)\n",
        "np.random.seed(155)\n",
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,\n",
        "                                     initial_epoch=0)\n",
        "print(my_first_nn.summary())\n",
        "print(my_first_nn.evaluate(X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1lpbok12kV_",
        "outputId": "a4d793f2-cfba-4923-a58c-73f343157189"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 2ms/step - loss: 8.4312 - acc: 0.3993\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 5.7085 - acc: 0.4392\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 4.3355 - acc: 0.4878\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 3.4337 - acc: 0.5226\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.7910 - acc: 0.5538\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 2.3434 - acc: 0.5608\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.9509 - acc: 0.5938\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.5587 - acc: 0.5938\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2463 - acc: 0.6128\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0478 - acc: 0.6406\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8961 - acc: 0.6510\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8330 - acc: 0.6476\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7884 - acc: 0.6615\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8237 - acc: 0.6476\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7673 - acc: 0.6823\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7349 - acc: 0.6632\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7704 - acc: 0.6840\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7756 - acc: 0.6823\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7123 - acc: 0.6997\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7073 - acc: 0.6823\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6978 - acc: 0.6736\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6912 - acc: 0.7031\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6995 - acc: 0.6875\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6793 - acc: 0.6910\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6692 - acc: 0.7101\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6799 - acc: 0.7049\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6755 - acc: 0.6910\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6752 - acc: 0.7101\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6620 - acc: 0.7170\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6465 - acc: 0.7101\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6403 - acc: 0.7170\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6401 - acc: 0.7240\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6354 - acc: 0.7205\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6510 - acc: 0.7014\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6376 - acc: 0.7083\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6386 - acc: 0.7049\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6245 - acc: 0.7135\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6140 - acc: 0.7240\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6230 - acc: 0.7101\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6553 - acc: 0.7049\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6263 - acc: 0.7170\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6191 - acc: 0.7257\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6122 - acc: 0.7240\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6281 - acc: 0.7083\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6376 - acc: 0.6875\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6312 - acc: 0.7049\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6027 - acc: 0.7101\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6124 - acc: 0.7031\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5961 - acc: 0.7257\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5992 - acc: 0.7222\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5950 - acc: 0.7378\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5925 - acc: 0.7188\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6009 - acc: 0.7222\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5986 - acc: 0.7153\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6102 - acc: 0.7101\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6099 - acc: 0.7101\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5871 - acc: 0.7083\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5948 - acc: 0.7083\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5880 - acc: 0.7153\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5953 - acc: 0.7101\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5905 - acc: 0.7205\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5821 - acc: 0.7257\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6133 - acc: 0.7101\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6110 - acc: 0.7014\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5972 - acc: 0.7083\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5683 - acc: 0.7396\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5999 - acc: 0.7188\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5749 - acc: 0.7396\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5662 - acc: 0.7344\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5633 - acc: 0.7378\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5844 - acc: 0.7257\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5963 - acc: 0.7222\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5687 - acc: 0.7413\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5624 - acc: 0.7378\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5711 - acc: 0.7309\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5740 - acc: 0.7222\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5747 - acc: 0.7153\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5668 - acc: 0.7240\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5648 - acc: 0.7309\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5573 - acc: 0.7431\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5635 - acc: 0.7240\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5618 - acc: 0.7257\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5624 - acc: 0.7396\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6099 - acc: 0.7170\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5866 - acc: 0.7361\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5572 - acc: 0.7500\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5663 - acc: 0.7413\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5534 - acc: 0.7431\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5897 - acc: 0.7413\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5575 - acc: 0.7292\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5830 - acc: 0.7326\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5847 - acc: 0.7292\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5802 - acc: 0.7274\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5656 - acc: 0.7188\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5660 - acc: 0.7257\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5439 - acc: 0.7587\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5486 - acc: 0.7448\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5615 - acc: 0.7413\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5606 - acc: 0.7361\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5556 - acc: 0.7274\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 20)                180       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 201 (804.00 Byte)\n",
            "Trainable params: 201 (804.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.6160 - acc: 0.6719\n",
            "[0.6160235404968262, 0.671875]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# a. Add more Dense layers to the existing code and check how the accuracy changes"
      ],
      "metadata": {
        "id": "t2cxbWuc3NyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer with input\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc']) # compilation\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,verbose=0, initial_epoch=0) # Training\n",
        "print(my_first_nn.summary()) #Summary\n",
        "print(my_first_nn.evaluate(X_test, Y_test)) #Evaluating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdvsgEOz3TJG",
        "outputId": "cc12b5cc-8a3f-49be-b89a-a7c144b33730"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 20)                180       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1041 (4.07 KB)\n",
            "Trainable params: 1041 (4.07 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.5678 - acc: 0.7240\n",
            "[0.5677953362464905, 0.7239583134651184]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer with input\n",
        "my_first_nn.add(Dense(22, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(24, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc']) # compilation\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,verbose=0, initial_epoch=0) # Training\n",
        "print(my_first_nn.summary()) #Summary\n",
        "print(my_first_nn.evaluate(X_test, Y_test)) #Evaluating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbLkRv143VKy",
        "outputId": "ddca4faf-faa9-4729-a22c-eac0e1933c0d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 20)                180       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 22)                462       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 24)                552       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1219 (4.76 KB)\n",
            "Trainable params: 1219 (4.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5688 - acc: 0.7188\n",
            "[0.5688223242759705, 0.71875]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BRNY9gIK3Zbe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}